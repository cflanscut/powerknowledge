{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "import os.path as osp\n",
    "\n",
    "# 导入模块\n",
    "import time\n",
    "from sklearn import cluster\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import shap\n",
    "\n",
    "source_dir = osp.join(osp.abspath('..'), 'data', 'source')\n",
    "\n",
    "\n",
    "def read_index(type, header='appliance'):\n",
    "    \"\"\"\n",
    "    读取给定type所包含的样本序号。如：读取load里面'R','I','NL'对应的设备序号有哪些\n",
    "    :param type: 需要查询的标签名\n",
    "    :param header: 对应的json里面的键，默认appliance\n",
    "    \"\"\"\n",
    "    with open(osp.join(source_dir, 'metadata_submetered2.1.json'),\n",
    "              'r',\n",
    "              encoding='utf8') as load_meta:\n",
    "        meta = json.load(load_meta)\n",
    "        metadata_len = len(meta)\n",
    "        label_index = {}\n",
    "        for i in range(metadata_len):\n",
    "            try:\n",
    "                label = meta[str(i + 1)][header][str(type)]\n",
    "            except NameError:\n",
    "                print('第{}个样本没有属性{}'.format(i + 1, type))\n",
    "            else:\n",
    "                if label in label_index.keys():\n",
    "                    label_index[label].append(i + 1)\n",
    "                else:\n",
    "                    label_index[label] = [i + 1]\n",
    "        return label_index\n",
    "\n",
    "\n",
    "# test read_index\n",
    "# ri = read_index('type', header=\"appliance\")\n",
    "# print(ri)\n",
    "\n",
    "\n",
    "def read_correlation(name,\n",
    "                     type,\n",
    "                     name_header='appliance',\n",
    "                     type_header='appliance'):\n",
    "\n",
    "    with open(osp.join(source_dir, 'metadata_submetered2.1.json'),\n",
    "              'r',\n",
    "              encoding='utf8') as load_meta:\n",
    "        meta = json.load(load_meta)\n",
    "        metadata_len = len(meta)\n",
    "        name_type = {}\n",
    "        for i in range(metadata_len):\n",
    "            try:\n",
    "                name_label = meta[str(i + 1)][name_header][str(name)]\n",
    "                type_label = meta[str(i + 1)][type_header][str(type)]\n",
    "            except NameError:\n",
    "                print('第{}个样本没有属性{}或{}'.format(i + 1, name, type))\n",
    "            else:\n",
    "                if name_label in name_type.keys():\n",
    "                    if type_label in name_type[name_label]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        name_type[name_label].append(type_label)\n",
    "                else:\n",
    "                    name_type[name_label] = []\n",
    "                    name_type[name_label].append(type_label)\n",
    "        return name_type\n",
    "\n",
    "\n",
    "# test\n",
    "# rc = read_correlation('type', 'brand')\n",
    "# print(rc)\n",
    "\n",
    "\n",
    "def read_processed_data(type,\n",
    "                        type_header='appliance',\n",
    "                        selected_label=[],\n",
    "                        offset=0,\n",
    "                        direaction=0,\n",
    "                        each_lenth=1,\n",
    "                        feature_select=None,\n",
    "                        Transformer=None,\n",
    "                        source='submetered_process',\n",
    "                        json_name='metadata_submetered2.1.json'):\n",
    "    file_dir = osp.join(source_dir, source)\n",
    "    json_dir = osp.join(source_dir, json_name)\n",
    "    meta = None\n",
    "    with open(json_dir, 'r', encoding='utf8') as load_meta:\n",
    "        meta = json.load(load_meta)\n",
    "\n",
    "    csv_list = os.listdir(file_dir)\n",
    "    first_data = pd.read_csv(os.path.join(file_dir, csv_list[0]))\n",
    "    features = first_data.keys()\n",
    "    feature_len = 0\n",
    "    if feature_select is not None:\n",
    "        try:\n",
    "            feature_index = features.get_indexer(feature_select)\n",
    "            feature_index = feature_index.tolist()\n",
    "        except IndexError:\n",
    "            print('there is no feature-selected in data')\n",
    "    if feature_select is None:\n",
    "        feature_len = len(features)\n",
    "    else:\n",
    "        try:\n",
    "            feature_len = len(feature_select)\n",
    "        except TypeError:\n",
    "            print('feature_select需为所选特征数组')\n",
    "    x = np.zeros((len(csv_list) * each_lenth, feature_len))\n",
    "    y = np.zeros((len(csv_list) * each_lenth))\n",
    "    index = np.zeros((len(csv_list) * each_lenth, 2))\n",
    "    for i, file in enumerate(csv_list):\n",
    "        if feature_select is None:\n",
    "            data = pd.read_csv(os.path.join(file_dir, file))\n",
    "        else:\n",
    "            data = pd.read_csv(\n",
    "                os.path.join(file_dir, file),\n",
    "                usecols=feature_index,\n",
    "            )\n",
    "        num = file[0:-4]\n",
    "        data_len = len(data)\n",
    "        try:\n",
    "            label = meta[num][type_header][type]\n",
    "        except TypeError:\n",
    "            print('没有该属性')\n",
    "        if selected_label != []:\n",
    "            if label not in selected_label:\n",
    "                continue\n",
    "        if direaction == 0:\n",
    "            for j in range(each_lenth):\n",
    "                x[i * each_lenth + j, :] = data.loc[offset + j]\n",
    "                index[i * each_lenth + j, 0] = num\n",
    "                index[i * each_lenth + j, 1] = offset + j\n",
    "                if Transformer is not None:\n",
    "                    y[i * each_lenth + j] = Transformer[label]\n",
    "                else:\n",
    "                    y = y.astype(np.str)\n",
    "                    y[i * each_lenth + j] = label\n",
    "        else:\n",
    "            for j in range(each_lenth):\n",
    "                x[i * each_lenth + j, :] = data.loc[data_len - offset - j - 1]\n",
    "                index[i * each_lenth + j, 0] = num\n",
    "                index[i * each_lenth + j, 1] = data_len - offset - j + 1\n",
    "                if Transformer is not None:\n",
    "                    y[i * each_lenth + j] = Transformer[label]\n",
    "                else:\n",
    "                    y = y.astype(np.str)\n",
    "                    y[i * each_lenth + j] = label\n",
    "    idx = np.argwhere(np.all(x[:, ...] == 0, axis=1))\n",
    "    x = np.delete(x, idx, axis=0)\n",
    "    y = np.delete(y, idx, axis=0)\n",
    "    index = np.delete(index, idx, axis=0)\n",
    "    x = np.nan_to_num(x)\n",
    "    x[x > 10000] = 10000\n",
    "    return x, y, index\n",
    "\n",
    "\n",
    "def get_feature_name(dir='submetered_process2'):\n",
    "    dir = osp.join(source_dir, dir)\n",
    "    csv_list = os.listdir(dir)\n",
    "    first_file = pd.read_csv(os.path.join(dir, csv_list[0]))\n",
    "    features = first_file.keys()\n",
    "    features = list(features)\n",
    "    del features[0]\n",
    "    return features\n",
    "\n",
    "\n",
    "# 输入点列表，返回所有边\n",
    "def calc_edge(Node_list):\n",
    "    edge_list = []\n",
    "    for node_A in Node_list:\n",
    "        for node_B in Node_list:\n",
    "            if node_B == node_A:\n",
    "                continue\n",
    "            edge_list.append(node_A + ',' + node_B)\n",
    "    return edge_list\n",
    "\n",
    "\n",
    "# 记录边的重复出现次数\n",
    "def count_edge(edge_count_dict, edge_list):\n",
    "    for edge in edge_list:\n",
    "        if edge not in edge_count_dict.keys():\n",
    "            edge_count_dict[edge] = 1\n",
    "        else:\n",
    "            edge_count_dict[edge] += 1\n",
    "    return edge_count_dict  # key为边，格式为'%03d,%03d'；value为出现的次数\n",
    "\n",
    "\n",
    "# 记录点的重复出现次数\n",
    "def count_node(node_count_dict, node_list):  # node为字符串型\n",
    "    for node in node_list:\n",
    "        if node not in node_count_dict.keys():\n",
    "            node_count_dict[node] = 1\n",
    "        else:\n",
    "            node_count_dict[node] += 1\n",
    "    return node_count_dict\n",
    "\n",
    "\n",
    "def save_graph_in_txt(file_dir, node_counts, edge_counts, graph_label) -> None:\n",
    "    with open(osp.join(file_dir, 'PLAIDG_node_labels.txt'),\n",
    "              'r') as file_node_labels:\n",
    "        base_node_num = len(file_node_labels.readlines())\n",
    "    with open(osp.join(file_dir, 'PLAIDG_graph_labels.txt'),\n",
    "              'r') as file_graph_label:\n",
    "        base_graph_num = len(file_graph_label.readlines())\n",
    "    with open(osp.join(file_dir, 'PLAIDG_graph_labels.txt'),\n",
    "              'a') as file_graph_label:\n",
    "        file_graph_label.write(str(graph_label) + '\\n')\n",
    "    tmp = 1\n",
    "    index_convert = {}\n",
    "    for key in node_counts.keys():  # key为节点类型，变成label；value为次数，变成attribute\n",
    "        feat = key.split(':')[0]\n",
    "        cluster = key.split(':')[1]\n",
    "        with open(osp.join(file_dir, 'PLAIDG_node_labels.txt'),\n",
    "                  'a') as file_node_labels:\n",
    "            # file_node_labels.write(str(key) + '\\n')  #指示当前节点的标签（特征+中心所对应的编号）\n",
    "            file_node_labels.write(str(feat) + '\\n')\n",
    "        with open(osp.join(file_dir, 'PLAIDG_node_attributes.txt'),\n",
    "                  'a') as file_node_attributes:\n",
    "            file_node_attributes.write(str(cluster) + '\\n')  # 指示当前节点的聚类值\n",
    "        with open(osp.join(file_dir, 'PLAIDG_graph_indicator.txt'),\n",
    "                  'a') as file_graph_indicator:\n",
    "            file_graph_indicator.write(str(base_graph_num + 1) +\n",
    "                                       '\\n')  # 指示当前节点属于第几个graph\n",
    "        index_convert[key] = str(base_node_num + tmp)  # 用于描述A矩阵，重新定义边的节点编号\n",
    "        tmp += 1\n",
    "    for key in edge_counts.keys():  # key为节点对，变成A阵；value为次数，变成attribute\n",
    "        key_str = key.split(',')\n",
    "        node_a = index_convert[key_str[0]]\n",
    "        node_b = index_convert[key_str[1]]\n",
    "        with open(osp.join(file_dir, 'PLAIDG_A.txt'), 'a') as file_A:\n",
    "            file_A.write(node_b + ',' + node_a + '\\n')  # 通用数据集都是第二列顺序排列的\n",
    "        with open(osp.join(file_dir, 'PLAIDG_edge_attributes.txt'),\n",
    "                  'a') as file_edge_attributes:\n",
    "            file_edge_attributes.write(str(edge_counts[key]) + '\\n')\n",
    "\n",
    "\n",
    "def generate_graph(x, y, dst_dir):\n",
    "    file_count = 0\n",
    "    for i, x_i_cluster in enumerate(x):\n",
    "        edge_counts = {}\n",
    "        node_counts = {}\n",
    "        y_label_tmp = y[i]\n",
    "        nodes_temp = []\n",
    "\n",
    "        for j, cluster_k in enumerate(x_i_cluster):  # j为特征编号,cluster_k为所属类别\n",
    "            cluster_k = int(cluster_k)\n",
    "            nodes_temp.append('%02d:%02d' % (j, cluster_k))  # 节点编号为1-30\n",
    "\n",
    "        # calc edge\n",
    "        edge_list = calc_edge(nodes_temp)\n",
    "        edge_counts = count_edge(edge_counts, edge_list)\n",
    "        # calc node\n",
    "        node_counts = count_node(node_counts, nodes_temp)\n",
    "        save_graph_in_txt(dst_dir, node_counts, edge_counts, y_label_tmp)\n",
    "        # if i % each_file_len == (each_file_len - 1):\n",
    "        file_count += 1\n",
    "        if i % 100 == 0:\n",
    "            print('%04d/%04d' % (file_count, int(len(y) / each_file_len)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading data, cost 9.717s\n",
      "Original Accuracy : 0.8222\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x972 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 读取数据\n",
    "\n",
    "start_reading_time = time.time()\n",
    "source_file_pack = 'submetered_zengj'\n",
    "# feature_select = [\n",
    "#     'i_mean', 'i_wave_factor', 'i_pp_rms', 'i_thd', 'pure_thd', 'P', 'Q',\n",
    "#     'P_F', 'i_hp1', 'z_hp1', 'i_hm2', 'z_hm2', 'i_hp2', 'z_hp2', 'i_hm3',\n",
    "#     'z_hm3', 'i_hp3', 'z_hp3', 'i_hm4', 'z_hm4', 'i_hp4', 'z_hp4', 'i_hm5',\n",
    "#     'z_hm5', 'i_hp5', 'z_hp5', 'i_hm6', 'z_hm6', 'i_hp6', 'z_hp6', 'i_hm7',\n",
    "#     'z_hm7', 'i_hp7', 'z_hp7'\n",
    "# ]  # 选择所用特征量\n",
    "\n",
    "feature_select = get_feature_name(dir=osp.join(source_file_pack, 'total'))\n",
    "\n",
    "selected_label = [\n",
    "    'Air Conditioner', 'Blender', 'Coffee maker', 'Compact Fluorescent Lamp',\n",
    "    'Fan', 'Fridge', 'Hair Iron', 'Hairdryer', 'Heater',\n",
    "    'Incandescent Light Bulb', 'Laptop', 'Microwave', 'Soldering Iron',\n",
    "    'Vacuum', 'Washing Machine', 'Water kettle'\n",
    "]  # 选择所用电器\n",
    "\n",
    "load_transformer = {}\n",
    "num = 0\n",
    "for item in selected_label:\n",
    "    load_transformer[item] = num\n",
    "    num += 1\n",
    "\n",
    "each_file_len = 20\n",
    "\n",
    "x_train, y_train, index_train = read_processed_data(\n",
    "    'type',\n",
    "    type_header='appliance',\n",
    "    selected_label=selected_label,\n",
    "    direaction=1,\n",
    "    offset=0,\n",
    "    each_lenth=each_file_len,\n",
    "    feature_select=feature_select,\n",
    "    Transformer=load_transformer,\n",
    "    source=osp.join(source_file_pack, 'training'))  # 读取训练数据\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "x_validation, y_validation, index_validation = read_processed_data(\n",
    "    'type',\n",
    "    type_header='appliance',\n",
    "    selected_label=selected_label,\n",
    "    direaction=1,\n",
    "    offset=0,\n",
    "    each_lenth=each_file_len,\n",
    "    feature_select=feature_select,\n",
    "    Transformer=load_transformer,\n",
    "    source=osp.join(source_file_pack, 'validation'))  # 读取验证数据\n",
    "y_validation = y_validation.reshape(-1, 1)\n",
    "\n",
    "x_trainval = np.concatenate((x_train, x_validation), axis=0)\n",
    "y_trainval = np.concatenate((y_train, y_validation), axis=0)\n",
    "y_trainval = y_trainval.ravel()\n",
    "\n",
    "x_test, y_test, index_test = read_processed_data('type',\n",
    "                                                 type_header='appliance',\n",
    "                                                 selected_label=selected_label,\n",
    "                                                 direaction=1,\n",
    "                                                 offset=0,\n",
    "                                                 each_lenth=each_file_len,\n",
    "                                                 feature_select=feature_select,\n",
    "                                                 Transformer=load_transformer,\n",
    "                                                 source=osp.join(\n",
    "                                                     source_file_pack,\n",
    "                                                     'testing'))  # 读取测试数据\n",
    "y_test = y_test.ravel()\n",
    "print('finished loading data, cost %.3fs' % (time.time() - start_reading_time))\n",
    "\n",
    "\n",
    "# 原始数据进行随机深林\n",
    "rf_base = RandomForestClassifier()\n",
    "rf_base.fit(x_trainval, y_trainval)\n",
    "y_test_pred = rf_base.predict(x_test)\n",
    "print(\"Original Accuracy : %.4g\" % metrics.accuracy_score(y_test, y_test_pred))\n",
    "explainer = shap.TreeExplainer(rf_base)\n",
    "shap_values = explainer.shap_values(x_trainval)\n",
    "shap.summary_plot(shap_values, feature_select, plot_type='bar', max_display=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始数据进行集成学习，观察每个变量的shap值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading data, cost 31.546s\n",
      "01: Cluster Accuracy : 0.1312\n",
      "02: Cluster Accuracy : 0.5992\n",
      "03: Cluster Accuracy : 0.7515\n",
      "04: Cluster Accuracy : 0.7212\n",
      "05: Cluster Accuracy : 0.792\n",
      "06: Cluster Accuracy : 0.7739\n",
      "07: Cluster Accuracy : 0.7752\n",
      "08: Cluster Accuracy : 0.7501\n",
      "09: Cluster Accuracy : 0.7564\n",
      "10: Cluster Accuracy : 0.7996\n",
      "11: Cluster Accuracy : 0.7742\n",
      "12: Cluster Accuracy : 0.7445\n",
      "13: Cluster Accuracy : 0.7953\n",
      "14: Cluster Accuracy : 0.7237\n",
      "15: Cluster Accuracy : 0.7307\n",
      "16: Cluster Accuracy : 0.7082\n",
      "17: Cluster Accuracy : 0.7115\n",
      "18: Cluster Accuracy : 0.6796\n",
      "19: Cluster Accuracy : 0.7066\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "\n",
    "start_reading_time = time.time()\n",
    "source_file_pack = 'submetered_zengj'\n",
    "# feature_select = [\n",
    "#     'i_mean', 'i_wave_factor', 'i_pp_rms', 'i_thd', 'pure_thd', 'P', 'Q',\n",
    "#     'P_F', 'i_hp1', 'z_hp1', 'i_hm2', 'z_hm2', 'i_hp2', 'z_hp2', 'i_hm3',\n",
    "#     'z_hm3', 'i_hp3', 'z_hp3', 'i_hm4', 'z_hm4', 'i_hp4', 'z_hp4', 'i_hm5',\n",
    "#     'z_hm5', 'i_hp5', 'z_hp5', 'i_hm6', 'z_hm6', 'i_hp6', 'z_hp6', 'i_hm7',\n",
    "#     'z_hm7', 'i_hp7', 'z_hp7'\n",
    "# ]  # 选择所用特征量\n",
    "\n",
    "feature_select = get_feature_name(dir=osp.join(source_file_pack, 'total'))\n",
    "\n",
    "selected_label = [\n",
    "    'Air Conditioner', 'Blender', 'Coffee maker', 'Compact Fluorescent Lamp',\n",
    "    'Fan', 'Fridge', 'Hair Iron', 'Hairdryer', 'Heater',\n",
    "    'Incandescent Light Bulb', 'Laptop', 'Microwave', 'Soldering Iron',\n",
    "    'Vacuum', 'Washing Machine', 'Water kettle'\n",
    "]  # 选择所用电器\n",
    "\n",
    "load_transformer = {}\n",
    "num = 0\n",
    "for item in selected_label:\n",
    "    load_transformer[item] = num\n",
    "    num += 1\n",
    "\n",
    "\n",
    "x_train, y_train, index_train = read_processed_data(\n",
    "    'type',\n",
    "    type_header='appliance',\n",
    "    selected_label=selected_label,\n",
    "    direaction=1,\n",
    "    offset=0,\n",
    "    each_lenth=each_file_len,\n",
    "    feature_select=feature_select,\n",
    "    Transformer=load_transformer,\n",
    "    source=osp.join(source_file_pack, 'training'))  # 读取训练数据\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "x_validation, y_validation, index_validation = read_processed_data(\n",
    "    'type',\n",
    "    type_header='appliance',\n",
    "    selected_label=selected_label,\n",
    "    direaction=1,\n",
    "    offset=0,\n",
    "    each_lenth=each_file_len,\n",
    "    feature_select=feature_select,\n",
    "    Transformer=load_transformer,\n",
    "    source=osp.join(source_file_pack, 'validation'))  # 读取验证数据\n",
    "y_validation = y_validation.reshape(-1, 1)\n",
    "\n",
    "x_trainval = np.concatenate((x_train, x_validation), axis=0)\n",
    "y_trainval = np.concatenate((y_train, y_validation), axis=0)\n",
    "y_trainval = y_trainval.ravel()\n",
    "\n",
    "x_test, y_test, index_test = read_processed_data('type',\n",
    "                                                 type_header='appliance',\n",
    "                                                 selected_label=selected_label,\n",
    "                                                 direaction=1,\n",
    "                                                 offset=0,\n",
    "                                                 each_lenth=each_file_len,\n",
    "                                                 feature_select=feature_select,\n",
    "                                                 Transformer=load_transformer,\n",
    "                                                 source=osp.join(\n",
    "                                                     source_file_pack,\n",
    "                                                     'testing'))  # 读取测试数据\n",
    "y_test = y_test.ravel()\n",
    "print('finished loading data, cost %.3fs' % (time.time() - start_reading_time))\n",
    "\n",
    "\n",
    "# 特征值聚类识别\n",
    "center_record = {}\n",
    "centers = {}\n",
    "feature_lens = 30  # 应该改成len函数取值\n",
    "\n",
    "for n_cluster in range(2, 20):\n",
    "    data_train = y_trainval.reshape(-1, 1)\n",
    "    data_test = y_test.reshape(-1, 1)\n",
    "    for f_index in range(feature_lens):  #\n",
    "        # n_cluster = 4 * (2 * feature_lens - 2 * f_index) - 4 # 按照数圈的方式制定聚类中心\n",
    "        # n_cluster = 20\n",
    "        km = KMeans(n_clusters=n_cluster, random_state=1)\n",
    "        if f_index in [5, 6]:  # 只有这两个特征（功率）需要取对数\n",
    "            x_trainval_f = np.log(x_trainval[:, f_index]).reshape(-1, 1)\n",
    "            x_test_f = np.log(x_test[:, f_index]).reshape(-1, 1)\n",
    "        x_trainval_f = x_trainval[:, f_index].reshape(-1, 1)\n",
    "        x_test_f = x_test[:, f_index].reshape(-1, 1)\n",
    "        # 对训练集进行聚类\n",
    "        x_trainval_cluster = km.fit_predict(x_trainval_f).reshape(\n",
    "            -1, 1)  # 这里的y只是kmean里面的聚类中心编号，不是从小到大排列下来的编号\n",
    "        data_train = np.concatenate((data_train, x_trainval_cluster), axis=1)\n",
    "        # 对测试集进行聚类转化\n",
    "        x_test_cluster = km.predict(x_test_f).reshape(-1, 1)  # 直接预测就行，不需要fit\n",
    "        data_test = np.concatenate((data_test, x_test_cluster), axis=1)\n",
    "        # 记录聚类中心和排序\n",
    "        centers[f_index] = [i for item in km.cluster_centers_\n",
    "                            for i in item]  # item是个数组，如果只有1维，再加个循环读取数值\n",
    "        center_record[f_index] = np.argsort(\n",
    "            centers[f_index]\n",
    "        )  # 对kmeans得到的聚类中心从小到大进行排序，得到排序index，即center[record[0]]为中心最小值\n",
    "\n",
    "    rf_cluster = RandomForestClassifier()\n",
    "    rf_cluster.fit(data_train[:, 1:], data_train[:, 0])\n",
    "    y_test_pred = rf_cluster.predict(data_test[:, 1:])\n",
    "    print(\"%02d: Cluster Accuracy : %.4g\" %\n",
    "          (n_cluster, metrics.accuracy_score(data_test[:, 0], y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对所有的变量进行聚类再来进行集成学习，并没有多大改善。原因是集成学习本身就含有大量分箱的操作，进行聚类有些多此一举。尝试一下对聚类的数据进行构图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构图的思路是，节点顺序为特征顺序，特征为聚类点，边为啥？这里所有节点都是特征，边是解释特征之间的连接的。每一层GCN不一定都一样全连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading data, cost 8.987s\n",
      "0001/0564\n",
      "0101/0564\n",
      "0201/0564\n",
      "0301/0564\n",
      "0401/0564\n",
      "0501/0564\n",
      "0601/0564\n",
      "0701/0564\n",
      "0801/0564\n",
      "0901/0564\n",
      "1001/0564\n",
      "1101/0564\n",
      "1201/0564\n",
      "1301/0564\n",
      "1401/0564\n",
      "1501/0564\n",
      "1601/0564\n",
      "1701/0564\n",
      "1801/0564\n",
      "1901/0564\n",
      "2001/0564\n",
      "2101/0564\n",
      "2201/0564\n",
      "2301/0564\n",
      "2401/0564\n",
      "2501/0564\n",
      "2601/0564\n",
      "2701/0564\n",
      "2801/0564\n",
      "2901/0564\n",
      "3001/0564\n",
      "3101/0564\n",
      "3201/0564\n",
      "3301/0564\n",
      "3401/0564\n",
      "3501/0564\n",
      "3601/0564\n",
      "3701/0564\n",
      "3801/0564\n",
      "3901/0564\n",
      "4001/0564\n",
      "4101/0564\n",
      "4201/0564\n",
      "4301/0564\n",
      "4401/0564\n",
      "4501/0564\n",
      "4601/0564\n",
      "4701/0564\n",
      "4801/0564\n",
      "4901/0564\n",
      "5001/0564\n",
      "5101/0564\n",
      "5201/0564\n",
      "5301/0564\n",
      "5401/0564\n",
      "5501/0564\n",
      "5601/0564\n"
     ]
    }
   ],
   "source": [
    "start_reading_time = time.time()\n",
    "source_file_pack = 'submetered_zengj'\n",
    "# feature_select = [\n",
    "#     'i_mean', 'i_wave_factor', 'i_pp_rms', 'i_thd', 'pure_thd', 'P', 'Q',\n",
    "#     'P_F', 'i_hp1', 'z_hp1', 'i_hm2', 'z_hm2', 'i_hp2', 'z_hp2', 'i_hm3',\n",
    "#     'z_hm3', 'i_hp3', 'z_hp3', 'i_hm4', 'z_hm4', 'i_hp4', 'z_hp4', 'i_hm5',\n",
    "#     'z_hm5', 'i_hp5', 'z_hp5', 'i_hm6', 'z_hm6', 'i_hp6', 'z_hp6', 'i_hm7',\n",
    "#     'z_hm7', 'i_hp7', 'z_hp7'\n",
    "# ]  # 选择所用特征量\n",
    "\n",
    "feature_select = get_feature_name(dir=osp.join(source_file_pack, 'total'))\n",
    "\n",
    "selected_label = [\n",
    "    'Air Conditioner', 'Blender', 'Coffee maker', 'Compact Fluorescent Lamp',\n",
    "    'Fan', 'Fridge', 'Hair Iron', 'Hairdryer', 'Heater',\n",
    "    'Incandescent Light Bulb', 'Laptop', 'Microwave', 'Soldering Iron',\n",
    "    'Vacuum', 'Washing Machine', 'Water kettle'\n",
    "]  # 选择所用电器\n",
    "\n",
    "load_transformer = {}\n",
    "num = 0\n",
    "for item in selected_label:\n",
    "    load_transformer[item] = num\n",
    "    num += 1\n",
    "each_file_len = 10\n",
    "\n",
    "x_train, y_train, index_train = read_processed_data(\n",
    "    'type',\n",
    "    type_header='appliance',\n",
    "    selected_label=selected_label,\n",
    "    direaction=1,\n",
    "    offset=0,\n",
    "    each_lenth=each_file_len,\n",
    "    feature_select=feature_select,\n",
    "    Transformer=load_transformer,\n",
    "    source=osp.join(source_file_pack, 'training'))  # 读取训练数据\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "x_validation, y_validation, index_validation = read_processed_data(\n",
    "    'type',\n",
    "    type_header='appliance',\n",
    "    selected_label=selected_label,\n",
    "    direaction=1,\n",
    "    offset=0,\n",
    "    each_lenth=each_file_len,\n",
    "    feature_select=feature_select,\n",
    "    Transformer=load_transformer,\n",
    "    source=osp.join(source_file_pack, 'validation'))  # 读取验证数据\n",
    "y_validation = y_validation.reshape(-1, 1)\n",
    "\n",
    "x_trainval = np.concatenate((x_train, x_validation), axis=0)\n",
    "y_trainval = np.concatenate((y_train, y_validation), axis=0)\n",
    "y_trainval = y_trainval.ravel()\n",
    "\n",
    "x_test, y_test, index_test = read_processed_data('type',\n",
    "                                                 type_header='appliance',\n",
    "                                                 selected_label=selected_label,\n",
    "                                                 direaction=1,\n",
    "                                                 offset=0,\n",
    "                                                 each_lenth=each_file_len,\n",
    "                                                 feature_select=feature_select,\n",
    "                                                 Transformer=load_transformer,\n",
    "                                                 source=osp.join(\n",
    "                                                     source_file_pack,\n",
    "                                                     'testing'))  # 读取测试数据\n",
    "y_test = y_test.ravel()\n",
    "print('finished loading data, cost %.3fs' % (time.time() - start_reading_time))\n",
    "\n",
    "# 特征值聚类识别\n",
    "center_record = {}\n",
    "centers = {}\n",
    "feature_lens = len(feature_select)  # 应该改成len函数取值\n",
    "\n",
    "n_cluster = 10\n",
    "data_train = y_trainval.reshape(-1, 1)\n",
    "data_test = y_test.reshape(-1, 1)\n",
    "for f_index in range(feature_lens):  #\n",
    "    # n_cluster = 4 * (2 * feature_lens - 2 * f_index) - 4 # 按照数圈的方式制定聚类中心\n",
    "    # n_cluster = 20\n",
    "    km = KMeans(n_clusters=n_cluster, random_state=1)\n",
    "    if f_index in [5, 6]:  # 只有这两个特征（功率）需要取对数\n",
    "        x_trainval_f = np.log(x_trainval[:, f_index]).reshape(-1, 1)\n",
    "        x_test_f = np.log(x_test[:, f_index]).reshape(-1, 1)\n",
    "    x_trainval_f = x_trainval[:, f_index].reshape(-1, 1)\n",
    "    x_test_f = x_test[:, f_index].reshape(-1, 1)\n",
    "    # 对训练集进行聚类\n",
    "    x_trainval_cluster = km.fit_predict(x_trainval_f).reshape(\n",
    "        -1, 1)  # 这里的y只是kmean里面的聚类中心编号，不是从小到大排列下来的编号\n",
    "    data_train = np.concatenate((data_train, x_trainval_cluster), axis=1)\n",
    "    # 对测试集进行聚类转化\n",
    "    x_test_cluster = km.predict(x_test_f).reshape(-1, 1)  # 直接预测就行，不需要fit\n",
    "    data_test = np.concatenate((data_test, x_test_cluster), axis=1)\n",
    "    # 记录聚类中心和排序\n",
    "    centers[f_index] = [i for item in km.cluster_centers_\n",
    "                        for i in item]  # centers为各聚类中心的值\n",
    "    center_record[f_index] = np.argsort(\n",
    "        centers[f_index]\n",
    "    )  # 对kmeans得到的聚类中心从小到大进行排序，得到排序index，即center[record[0]]为中心最小值\n",
    "\n",
    "# train_dir = osp.join(osp.abspath(''), 'PLAIDG_single', 'PLAIDG_single',\n",
    "#                         'raw')\n",
    "test_dir = osp.join(osp.abspath(''), 'PLAIDG_single_test',\n",
    "                    'PLAIDG_single_test', 'raw')\n",
    "txt_list = [\n",
    "    'A', 'edge_attributes', 'graph_indicator', 'graph_labels',\n",
    "    'node_attributes', 'node_labels'\n",
    "]\n",
    "for txt in txt_list:\n",
    "    file_name = 'PLAIDG_' + txt + '.txt'\n",
    "    url = osp.join(test_dir, file_name)\n",
    "    open(url, 'w').close()\n",
    "\n",
    "generate_graph(data_test[:, 1:], data_test[:, 0], test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:loss 1233.67077 acc 0.08046\n",
      "epoch 1:loss 41.72126 acc 0.10023\n",
      "epoch 2:loss 7.74962 acc 0.11892\n",
      "epoch 3:loss 2.83141 acc 0.16769\n",
      "epoch 4:loss 2.72993 acc 0.17262\n",
      "epoch 5:loss 2.49022 acc 0.18292\n",
      "epoch 6:loss 2.50111 acc 0.18277\n",
      "epoch 7:loss 2.46706 acc 0.17954\n",
      "epoch 8:loss 2.45528 acc 0.18838\n",
      "epoch 9:loss 2.46090 acc 0.18023\n",
      "epoch 10:loss 2.53894 acc 0.18131\n",
      "epoch 11:loss 2.36147 acc 0.19169\n",
      "epoch 12:loss 2.34995 acc 0.19500\n",
      "epoch 13:loss 2.34249 acc 0.18700\n",
      "epoch 14:loss 2.37263 acc 0.18638\n",
      "epoch 15:loss 2.35174 acc 0.19077\n",
      "epoch 16:loss 2.29234 acc 0.19885\n",
      "epoch 17:loss 2.30645 acc 0.18862\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5696/1788091776.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    292\u001b[0m             y.size()[0])\n\u001b[0;32m    293\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.functional import Tensor\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.io import read_tu_data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PLAIDDataset(InMemoryDataset):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 name='PLAIDG_single',\n",
    "                 transform=None,\n",
    "                 pre_transform=None,\n",
    "                 pre_filter=None,\n",
    "                 use_edge_attr=False,\n",
    "                 use_node_label=False):\n",
    "        self.name = name\n",
    "        super(PLAIDDataset, self).__init__(root, transform, pre_transform,\n",
    "                                           pre_filter)  # 预处理在这里实现\n",
    "        self.data, self.slices = torch.load(\n",
    "            self.processed_paths[0])  # 读取处理好的数据\n",
    "        if self.data.x is not None and not use_node_label:\n",
    "            num_node_attributes = self.num_node_attributes\n",
    "            self.data.x = self.data.x[:, :num_node_attributes]\n",
    "        if self.data.edge_attr is not None and not use_edge_attr:\n",
    "            num_edge_attributes = self.num_edge_attributes\n",
    "            self.data.edge_attr = self.data.edge_attr[:,\n",
    "                                                      num_edge_attributes:]  # 不需要edge_attr，只要后面的label\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return osp.join(self.root, self.name, 'raw')  # join可以自动加斜杠\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return osp.join(self.root, self.name, 'processed')\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(\n",
    "        self\n",
    "    ):  #A list of files in the raw_dir which needs to be found in order to skip the download.\n",
    "        names = [\n",
    "            'A', 'edge_attributes', 'graph_indicator', 'graph_labels',\n",
    "            'node_attributes', 'node_labels'\n",
    "        ]\n",
    "        return ['{}_{}.txt'.format('PLAIDG', name) for name in names]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(\n",
    "        self\n",
    "    ):  #A list of files in the processed_dir which needs to be found in order to skip the processing.\n",
    "        return 'data.pt'\n",
    "\n",
    "    @property\n",
    "    def num_node_labels(self) -> int:\n",
    "        if self.data.x is None:\n",
    "            return 0\n",
    "        for i in range(self.data.x.size(1)):\n",
    "            x = self.data.x[:, i:]\n",
    "            if ((x == 0) | (x == 1)).all() and (x.sum(dim=1) == 1).all():\n",
    "                return self.data.x.size(1) - i\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def num_node_attributes(self) -> int:\n",
    "        if self.data.x is None:\n",
    "            return 0\n",
    "        return self.data.x.size(1) - self.num_node_labels\n",
    "\n",
    "    @property\n",
    "    def num_edge_labels(self) -> int:\n",
    "        if self.data.edge_attr is None:\n",
    "            return 0\n",
    "        for i in range(self.data.edge_attr.size(1)):\n",
    "            if self.data.edge_attr[:, i:].sum() == self.data.edge_attr.size(0):\n",
    "                return self.data.edge_attr.size(1) - i\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def num_edge_attributes(self) -> int:\n",
    "        if self.data.edge_attr is None:\n",
    "            return 0\n",
    "        return self.data.edge_attr.size(1) - self.num_edge_labels\n",
    "\n",
    "    def download(self):\n",
    "        print('This dataset is not yet public')\n",
    "\n",
    "    def process(self):\n",
    "        self.data, self.slices = read_tu_data(self.raw_dir, 'PLAIDG')\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [self.get(idx) for idx in range(len(self))]\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "            self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.get(idx) for idx in range(len(self))]  #拆成一个个单图\n",
    "            data_list = [self.pre_transform(data)\n",
    "                         for data in data_list]  #对每个单图进行pre_transform\n",
    "            self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "        torch.save((self.data, self.slices), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({})'.format(self.name, len(self))\n",
    "\n",
    "\n",
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim,\n",
    "        num_node_feats,\n",
    "        num_edge_feats,\n",
    "        num_class,\n",
    "        latent_dim=[2, 1],\n",
    "        k=34,\n",
    "        conv1d_channels=[1, 32],\n",
    "        conv1d_kws=[0, 5],  # 0是待定的意思\n",
    "        conv1d_activation='ReLU',\n",
    "    ):\n",
    "        super(DGCNN, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim  # 指的是图卷积里面的每个层的节点特征维度，最后一层为1，论文写着方便排序\n",
    "        self.output_dim = output_dim  # 指的是图卷积之后输出的维度，如果有dense则输出dense之后的，没有dense就输出dense\n",
    "        self.num_node_feats = num_node_feats  # dataset.num_node_features\n",
    "        self.num_edge_feats = num_edge_feats  # dataset.num_edge_features\n",
    "        self.k = k\n",
    "        self.total_latent_dim = sum(latent_dim)\n",
    "        conv1d_kws[0] = self.total_latent_dim  # 把所有图层拼接起来作为1-D卷积的输入\n",
    "        self.hidden_dim = int(math.sqrt(output_dim * num_class))\n",
    "\n",
    "        # GCN\n",
    "        self.conv1 = GCNConv(self.num_node_feats, self.latent_dim[0])\n",
    "        self.conv2 = GCNConv(self.latent_dim[0], self.latent_dim[1])\n",
    "        # self.conv3 = GCNConv(self.latent_dim[1], self.latent_dim[2])\n",
    "        # self.conv4 = GCNConv(self.latent_dim[2], self.latent_dim[3])\n",
    "\n",
    "        # conv1d\n",
    "        # self.conv1d_params1 = nn.Conv1d(\n",
    "        #     1, conv1d_channels[0], conv1d_kws[0],\n",
    "        #     conv1d_kws[0])  # 一维输入则通道为1，所有节点特征拼成1维了，核长等于步长，一步一个节点\n",
    "        # # self.maxpool1d = nn.MaxPool1d(2, 2)  # 窗口大小2，步长2，沿着一维的方向(类似于两个节点的输出取最大)\n",
    "        # # self.conv1d_params2 = nn.Conv1d(conv1d_channels[0], conv1d_channels[1],\n",
    "        # #                                 conv1d_kws[1], 1)\n",
    "        # # dense-layers\n",
    "        # dense_dim = int(\n",
    "        #     k)  # 这个跟池化的输出有关。如100个节点卷完第一层后变成100个数，再池化成50个节点（每个节点有embedding维度）\n",
    "        # self.dense_dim = (dense_dim) * conv1d_channels[\n",
    "        #     0]  # 一维的长度是池化后再一维卷，即dense-kws+1，然后再摊平，乘于channel（embedding）长度\n",
    "        self.conv1dlist = nn.ModuleList([\n",
    "            nn.Conv1d(1, conv1d_channels[0], conv1d_kws[0]) for i in range(k)\n",
    "        ])\n",
    "        self.dense_dim = k\n",
    "        if self.output_dim > 0:\n",
    "            self.out_params = nn.Linear(self.dense_dim, output_dim)  #最后加个全连接\n",
    "\n",
    "        self.conv1d_activation = eval('nn.{}()'.format(conv1d_activation))\n",
    "\n",
    "        # MLPClassifier\n",
    "        # self.h1_weights = nn.Linear(output_dim, self.hidden_dim)\n",
    "        # self.h2_weights = nn.Linear(self.hidden_dim, num_class)\n",
    "        self.h1_weights = nn.Linear(output_dim, num_class)\n",
    "\n",
    "        # initial parameter\n",
    "        # if needed\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_attr, edge_index = data.x, data.edge_attr, data.edge_index\n",
    "\n",
    "        graph_num = len(np.unique(\n",
    "            data.batch))  # len(np.unique(batch.batch))为batch中几个图\n",
    "        node_slice = torch.cumsum(torch.from_numpy(np.bincount(data.batch)), 0)\n",
    "        node_slice = torch.cat([torch.tensor([0]), node_slice])\n",
    "\n",
    "        # step 1: extra node-feature and node-index\n",
    "        # node_index = x[:, datasets.data.num_node_attributes:]\n",
    "        # x = x[:, :datasets.data.num_node_attributes]\n",
    "\n",
    "        # step 2: propagate the message via 4 GCN layers\n",
    "        out = self.conv1(x, edge_index)\n",
    "        # x = torch.cat([x, out], 1)\n",
    "        x = out\n",
    "        out = self.conv2(out, edge_index)\n",
    "        x = torch.cat([x, out], 1)\n",
    "        # out = self.conv3(out, edge_index)\n",
    "        # x = torch.cat([x, out], 1)\n",
    "        # out = self.conv4(out, edge_index)  # 最后一层GCN的输出，N*1维，作为sortpooling排序用\n",
    "        # x = torch.cat([x, out], 1)\n",
    "\n",
    "        # step 3: sortpooling layer\n",
    "        # 因为batch里不止一张图，所以要区分每个图单独进行sortpooling\n",
    "        # batch_sortpooling_graphs = torch.zeros(graph_num, self.k,\n",
    "        #                                        self.total_latent_dim)\n",
    "        # if torch.cuda.is_available() and isinstance(x, torch.cuda.FloatTensor):\n",
    "        #     batch_sortpooling_graphs = batch_sortpooling_graphs.cuda()\n",
    "\n",
    "        # for i in range(graph_num):\n",
    "        #     # to_sort = out[node_slice[i]:node_slice[i + 1]]  # 把当前graph的节点特征拿出来\n",
    "        #     # k = self.k if self.k <= node_slice[i + 1] - node_slice[\n",
    "        #     #     i] else node_slice[i + 1] - node_slice[i]  # 判断k和图节点数的大小关系\n",
    "        #     # _, topk_indices = to_sort.topk(k, dim=0)  # 返回前k个元素及对应的索引\n",
    "        #     topk_indices = Tensor(range(0, self.k))\n",
    "        #     topk_indices += node_slice[i]  # 定位到原始batch的索引\n",
    "        #     topk_indices = topk_indices.squeeze()\n",
    "        #     topk_indices = topk_indices.int()\n",
    "        #     sortpooling_graph = x.index_select(0, topk_indices)\n",
    "        #     # if k < self.k:\n",
    "        #     #     to_pad = torch.zeros(self.k - k, self.total_latent_dim)\n",
    "        #     #     if torch.cuda.is_available() and isinstance(\n",
    "        #     #             x, torch.cuda.FloatTensor):\n",
    "        #     #         to_pad = to_pad.cuda()\n",
    "        #     #     sortpooling_graph = torch.cat((sortpooling_graph, to_pad), 0)\n",
    "        #     batch_sortpooling_graphs[i] = sortpooling_graph\n",
    "\n",
    "        # step 4：traditional 1d convolution and dense layers\n",
    "        # to_conv1d = batch_sortpooling_graphs.view(\n",
    "        #     (-1, 1, self.k * self.total_latent_dim))  # 每个图变成1x1xk*totaldim的大小\n",
    "        to_conv1d = x.view(-1, self.k, self.total_latent_dim)\n",
    "        to_dense = torch.zeros(graph_num, self.k, 1)\n",
    "        for i, m in enumerate(self.conv1dlist):\n",
    "            # out = m(to_conv1d[:, i, :].view(-1, 1, self.total_latent_dim))\n",
    "            to_dense[:, i, :] = m(to_conv1d[:, i, :].view(\n",
    "                -1, 1, self.total_latent_dim)).view(-1, 1)\n",
    "        to_dense = to_dense.squeeze()\n",
    "        # conv1d_res = self.conv1d_params1(\n",
    "        #     to_conv1d\n",
    "        # )  # 一维卷积，一个图为一维向量，卷积核大小为单个节点特征长度，步长也为单个节点长度。输出长度为k，channel为16\n",
    "        # conv1d_res = self.conv1d_activation(conv1d_res)  # ReLU\n",
    "        # # conv1d_res = self.maxpool1d(conv1d_res)  # 窗口大小2，步长2，每个图为（k-2）/2+1\n",
    "        # # conv1d_res = self.conv1d_params2(\n",
    "        # #     conv1d_res\n",
    "        # # )  # 继续卷，这时候卷积核大小为5，步长1，输出channel为32，即一个位置有32维的embedding。长度为((k-2)/2+1)-5+1\n",
    "        # # conv1d_res = self.conv1d_activation(conv1d_res)  # ReLU\n",
    "\n",
    "        # to_dense = to_dense.view(graph_num,\n",
    "        #                          -1)  # 把channel拉平，变成G*上面的长度 x channel数\n",
    "\n",
    "        if self.output_dim > 0:\n",
    "            reluact_fp = self.out_params(to_dense)  # 如果有output_dim，加一个线性全连接\n",
    "            # reluact_fp = self.conv1d_activation(out_linear)  # ReLU\n",
    "        else:\n",
    "            reluact_fp = to_dense  # 如果没有就直接输出\n",
    "\n",
    "        # step 5: MLP classification\n",
    "        logits = self.h1_weights(reluact_fp)\n",
    "        # h1 = F.relu(h1)\n",
    "        # h1 = F.dropout(h1, training=self.training)\n",
    "        # logits = self.h2_weights(h1)\n",
    "        logits = F.log_softmax(logits, dim=1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def node_4edge_slice(self, edge_index):\n",
    "        row, _ = edge_index[0], edge_index[1]\n",
    "        row = row.cpu().numpy()\n",
    "        node_slice4edge = torch.cumsum(torch.from_numpy(np.bincount(row)), 0)\n",
    "        node_slice4edge = torch.cat([torch.tensor([0]), node_slice4edge])\n",
    "        return node_slice4edge\n",
    "\n",
    "\n",
    "path = osp.join(osp.abspath('..'), 'graph', 'PLAIDG_single')\n",
    "datasets = PLAIDDataset(root=path,\n",
    "                        name='PLAIDG_single',\n",
    "                        use_node_label=False,\n",
    "                        use_edge_attr=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DGCNN(20, datasets.num_node_features, datasets.num_edge_features,\n",
    "              datasets.num_classes).to(device)\n",
    "data = datasets.data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    loader = DataLoader(datasets, batch_size=100, shuffle=True)\n",
    "    total_loss = []\n",
    "    for batch in loader:\n",
    "        batch.to(device)\n",
    "        out = model(batch)\n",
    "        y = batch.y\n",
    "        loss = F.nll_loss(out, y)\n",
    "        pred = out.data.max(1, keepdim=True)[1]\n",
    "        acc = pred.eq(y.data.view_as(pred)).cpu().sum().item() / float(\n",
    "            y.size()[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.data.cpu().detach().numpy()\n",
    "        total_loss.append(np.array([loss, acc]) * len(y))\n",
    "\n",
    "    total_loss = np.array(total_loss)\n",
    "    avg_loss = np.sum(total_loss, 0) / len(datasets.data.y)\n",
    "    print('epoch %d:loss %.5f acc %.5f' % (epoch, avg_loss[0], avg_loss[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:loss 8.45025 acc 0.27908\n",
      "epoch 1:loss 2.49781 acc 0.56208\n",
      "epoch 2:loss 1.16714 acc 0.70208\n",
      "epoch 3:loss 0.76363 acc 0.77346\n",
      "epoch 4:loss 1.42245 acc 0.69062\n",
      "epoch 5:loss 0.80878 acc 0.78623\n",
      "epoch 6:loss 0.53147 acc 0.83215\n",
      "epoch 7:loss 0.43714 acc 0.85815\n",
      "epoch 8:loss 0.39809 acc 0.86692\n",
      "epoch 9:loss 0.37749 acc 0.87423\n",
      "epoch 10:loss 0.36288 acc 0.88115\n",
      "epoch 11:loss 0.35110 acc 0.88338\n",
      "epoch 12:loss 0.36115 acc 0.87962\n",
      "epoch 13:loss 0.37720 acc 0.87077\n",
      "epoch 14:loss 0.37389 acc 0.87138\n",
      "epoch 15:loss 0.35978 acc 0.87892\n",
      "epoch 16:loss 0.34575 acc 0.88177\n",
      "epoch 17:loss 0.34534 acc 0.88592\n",
      "epoch 18:loss 0.34802 acc 0.87746\n",
      "epoch 19:loss 0.37621 acc 0.86992\n",
      "epoch 20:loss 0.39116 acc 0.86308\n",
      "epoch 21:loss 0.38755 acc 0.87108\n",
      "epoch 22:loss 0.35534 acc 0.88231\n",
      "epoch 23:loss 0.35208 acc 0.87823\n",
      "epoch 24:loss 0.34183 acc 0.88423\n",
      "epoch 25:loss 0.34465 acc 0.88423\n",
      "epoch 26:loss 0.35043 acc 0.88177\n",
      "epoch 27:loss 0.36892 acc 0.87031\n",
      "epoch 28:loss 0.37166 acc 0.87146\n",
      "epoch 29:loss 0.35536 acc 0.87408\n",
      "epoch 30:loss 0.34010 acc 0.88408\n",
      "epoch 31:loss 0.34837 acc 0.87954\n",
      "epoch 32:loss 0.35568 acc 0.87977\n",
      "epoch 33:loss 0.33709 acc 0.88723\n",
      "epoch 34:loss 0.36432 acc 0.87415\n",
      "epoch 35:loss 0.34217 acc 0.88085\n",
      "epoch 36:loss 0.34808 acc 0.88162\n",
      "epoch 37:loss 0.34513 acc 0.88469\n",
      "epoch 38:loss 0.38315 acc 0.86769\n",
      "epoch 39:loss 0.36800 acc 0.87500\n",
      "epoch 40:loss 0.35303 acc 0.87992\n",
      "epoch 41:loss 0.36440 acc 0.87762\n",
      "epoch 42:loss 0.35552 acc 0.87900\n",
      "epoch 43:loss 0.38514 acc 0.86738\n",
      "epoch 44:loss 0.36662 acc 0.87823\n",
      "epoch 45:loss 0.37126 acc 0.86915\n",
      "epoch 46:loss 0.36408 acc 0.87815\n",
      "epoch 47:loss 0.37743 acc 0.87238\n",
      "epoch 48:loss 0.36360 acc 0.87169\n",
      "epoch 49:loss 0.36031 acc 0.88131\n",
      "epoch 50:loss 0.37016 acc 0.87162\n",
      "epoch 51:loss 0.36305 acc 0.87646\n",
      "epoch 52:loss 0.57310 acc 0.82354\n",
      "epoch 53:loss 0.45066 acc 0.84908\n",
      "epoch 54:loss 0.38595 acc 0.86623\n",
      "epoch 55:loss 0.36807 acc 0.87900\n",
      "epoch 56:loss 0.36988 acc 0.87215\n",
      "epoch 57:loss 0.34470 acc 0.88385\n",
      "epoch 58:loss 0.34461 acc 0.88231\n",
      "epoch 59:loss 0.36185 acc 0.87985\n",
      "epoch 60:loss 0.34601 acc 0.88092\n",
      "epoch 61:loss 0.35262 acc 0.88331\n",
      "epoch 62:loss 0.35595 acc 0.87169\n",
      "epoch 63:loss 0.36216 acc 0.87500\n",
      "epoch 64:loss 0.34273 acc 0.88254\n",
      "epoch 65:loss 0.34403 acc 0.88085\n",
      "epoch 66:loss 0.34323 acc 0.88200\n",
      "epoch 67:loss 0.33969 acc 0.88408\n",
      "epoch 68:loss 0.35331 acc 0.88015\n",
      "epoch 69:loss 0.36611 acc 0.87277\n",
      "epoch 70:loss 0.43599 acc 0.84708\n",
      "epoch 71:loss 0.44893 acc 0.84731\n",
      "epoch 72:loss 0.40068 acc 0.86077\n",
      "epoch 73:loss 0.41736 acc 0.85762\n",
      "epoch 74:loss 0.39501 acc 0.85923\n",
      "epoch 75:loss 0.38497 acc 0.86808\n",
      "epoch 76:loss 0.35731 acc 0.87808\n",
      "epoch 77:loss 0.37581 acc 0.87362\n",
      "epoch 78:loss 0.36082 acc 0.87723\n",
      "epoch 79:loss 0.37750 acc 0.87285\n",
      "epoch 80:loss 0.41137 acc 0.85762\n",
      "epoch 81:loss 0.41309 acc 0.86085\n",
      "epoch 82:loss 0.39193 acc 0.87169\n",
      "epoch 83:loss 0.41751 acc 0.85408\n",
      "epoch 84:loss 0.40059 acc 0.86515\n",
      "epoch 85:loss 0.42120 acc 0.85615\n",
      "epoch 86:loss 0.41217 acc 0.85762\n",
      "epoch 87:loss 0.38375 acc 0.86485\n",
      "epoch 88:loss 0.38915 acc 0.86592\n",
      "epoch 89:loss 0.38787 acc 0.86531\n",
      "epoch 90:loss 0.38549 acc 0.86677\n",
      "epoch 91:loss 0.38826 acc 0.87077\n",
      "epoch 92:loss 0.42482 acc 0.85685\n",
      "epoch 93:loss 0.42511 acc 0.84908\n",
      "epoch 94:loss 0.40656 acc 0.85600\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb4 in position 822: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame._handle_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\fx\\graph_module.py\u001b[0m in \u001b[0;36mpatched_getline\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_orig_getlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatched_getline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdatecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb4 in position 822: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5696/313164901.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.handle_user_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame._handle_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlineno\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\fx\\graph_module.py\u001b[0m in \u001b[0;36mpatched_getline\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_eval_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_orig_getlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatched_getline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdatecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mclearcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb4 in position 822: invalid start byte"
     ]
    }
   ],
   "source": [
    "from torch.functional import Tensor\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.io import read_tu_data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PLAIDDataset(InMemoryDataset):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 name='PLAIDG_single',\n",
    "                 transform=None,\n",
    "                 pre_transform=None,\n",
    "                 pre_filter=None,\n",
    "                 use_edge_attr=False,\n",
    "                 use_node_label=False):\n",
    "        self.name = name\n",
    "        super(PLAIDDataset, self).__init__(root, transform, pre_transform,\n",
    "                                           pre_filter)  # 预处理在这里实现\n",
    "        self.data, self.slices = torch.load(\n",
    "            self.processed_paths[0])  # 读取处理好的数据\n",
    "        if self.data.x is not None and not use_node_label:\n",
    "            num_node_attributes = self.num_node_attributes\n",
    "            self.data.x = self.data.x[:, :num_node_attributes]\n",
    "        if self.data.edge_attr is not None and not use_edge_attr:\n",
    "            num_edge_attributes = self.num_edge_attributes\n",
    "            self.data.edge_attr = self.data.edge_attr[:,\n",
    "                                                      num_edge_attributes:]  # 不需要edge_attr，只要后面的label\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return osp.join(self.root, self.name, 'raw')  # join可以自动加斜杠\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return osp.join(self.root, self.name, 'processed')\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(\n",
    "        self\n",
    "    ):  #A list of files in the raw_dir which needs to be found in order to skip the download.\n",
    "        names = [\n",
    "            'A', 'edge_attributes', 'graph_indicator', 'graph_labels',\n",
    "            'node_attributes', 'node_labels'\n",
    "        ]\n",
    "        return ['{}_{}.txt'.format('PLAIDG', name) for name in names]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(\n",
    "        self\n",
    "    ):  #A list of files in the processed_dir which needs to be found in order to skip the processing.\n",
    "        return 'data.pt'\n",
    "\n",
    "    @property\n",
    "    def num_node_labels(self) -> int:\n",
    "        if self.data.x is None:\n",
    "            return 0\n",
    "        for i in range(self.data.x.size(1)):\n",
    "            x = self.data.x[:, i:]\n",
    "            if ((x == 0) | (x == 1)).all() and (x.sum(dim=1) == 1).all():\n",
    "                return self.data.x.size(1) - i\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def num_node_attributes(self) -> int:\n",
    "        if self.data.x is None:\n",
    "            return 0\n",
    "        return self.data.x.size(1) - self.num_node_labels\n",
    "\n",
    "    @property\n",
    "    def num_edge_labels(self) -> int:\n",
    "        if self.data.edge_attr is None:\n",
    "            return 0\n",
    "        for i in range(self.data.edge_attr.size(1)):\n",
    "            if self.data.edge_attr[:, i:].sum() == self.data.edge_attr.size(0):\n",
    "                return self.data.edge_attr.size(1) - i\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def num_edge_attributes(self) -> int:\n",
    "        if self.data.edge_attr is None:\n",
    "            return 0\n",
    "        return self.data.edge_attr.size(1) - self.num_edge_labels\n",
    "\n",
    "    def download(self):\n",
    "        print('This dataset is not yet public')\n",
    "\n",
    "    def process(self):\n",
    "        self.data, self.slices = read_tu_data(self.raw_dir, 'PLAIDG')\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [self.get(idx) for idx in range(len(self))]\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "            self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.get(idx) for idx in range(len(self))]  #拆成一个个单图\n",
    "            data_list = [self.pre_transform(data)\n",
    "                         for data in data_list]  #对每个单图进行pre_transform\n",
    "            self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "        torch.save((self.data, self.slices), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({})'.format(self.name, len(self))\n",
    "\n",
    "\n",
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim,\n",
    "        num_node_feats,\n",
    "        num_edge_feats,\n",
    "        num_class,\n",
    "        latent_dim=[2, 1],\n",
    "        k=34,\n",
    "        conv1d_channels=[1, 32],\n",
    "        conv1d_kws=[0, 5],  # 0是待定的意思\n",
    "        conv1d_activation='ReLU',\n",
    "    ):\n",
    "        super(DGCNN, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim  # 指的是图卷积里面的每个层的节点特征维度，最后一层为1，论文写着方便排序\n",
    "        self.output_dim = output_dim  # 指的是图卷积之后输出的维度，如果有dense则输出dense之后的，没有dense就输出dense\n",
    "        self.num_node_feats = num_node_feats  # dataset.num_node_features\n",
    "        self.num_edge_feats = num_edge_feats  # dataset.num_edge_features\n",
    "        self.k = k\n",
    "        self.total_latent_dim = sum(latent_dim)\n",
    "        conv1d_kws[0] = self.total_latent_dim  # 把所有图层拼接起来作为1-D卷积的输入\n",
    "        self.hidden_dim = int(math.sqrt(output_dim * num_class))\n",
    "\n",
    "        # GCN\n",
    "        self.conv1 = GCNConv(self.num_node_feats, self.latent_dim[0])\n",
    "        self.conv2 = GCNConv(self.latent_dim[0], self.latent_dim[1])\n",
    "\n",
    "        self.conv1dlist = nn.ModuleList([\n",
    "            nn.Conv1d(1, conv1d_channels[0], conv1d_kws[0]) for i in range(k)\n",
    "        ])\n",
    "        self.dense_dim = k\n",
    "        if self.output_dim > 0:\n",
    "            self.out_params = nn.Linear(self.dense_dim, output_dim)  #最后加个全连接\n",
    "\n",
    "        self.conv1d_activation = eval('nn.{}()'.format(conv1d_activation))\n",
    "\n",
    "        # MLPClassifier\n",
    "        self.h1_weights = nn.Linear(output_dim, num_class)\n",
    "\n",
    "        # initial parameter\n",
    "        # if needed\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_attr, edge_index = data.x, data.edge_attr, data.edge_index\n",
    "\n",
    "        graph_num = len(np.unique(\n",
    "            data.batch))  # len(np.unique(batch.batch))为batch中几个图\n",
    "        node_slice = torch.cumsum(torch.from_numpy(np.bincount(data.batch)), 0)\n",
    "        node_slice = torch.cat([torch.tensor([0]), node_slice])\n",
    "\n",
    "        x = x.view(graph_num, -1)\n",
    "\n",
    "        # # step 2: propagate the message via 4 GCN layers\n",
    "        # out = self.conv1(x, edge_index)\n",
    "        # # x = torch.cat([x, out], 1)\n",
    "        # x = out\n",
    "        # out = self.conv2(out, edge_index)\n",
    "        # x = torch.cat([x, out], 1)\n",
    "        # out = self.conv3(out, edge_index)\n",
    "        # x = torch.cat([x, out], 1)\n",
    "        # out = self.conv4(out, edge_index)  # 最后一层GCN的输出，N*1维，作为sortpooling排序用\n",
    "        # x = torch.cat([x, out], 1)\n",
    "\n",
    "        # step 3: sortpooling layer\n",
    "        # 因为batch里不止一张图，所以要区分每个图单独进行sortpooling\n",
    "        # batch_sortpooling_graphs = torch.zeros(graph_num, self.k,\n",
    "        #                                        self.total_latent_dim)\n",
    "        # if torch.cuda.is_available() and isinstance(x, torch.cuda.FloatTensor):\n",
    "        #     batch_sortpooling_graphs = batch_sortpooling_graphs.cuda()\n",
    "\n",
    "        # for i in range(graph_num):\n",
    "        #     # to_sort = out[node_slice[i]:node_slice[i + 1]]  # 把当前graph的节点特征拿出来\n",
    "        #     # k = self.k if self.k <= node_slice[i + 1] - node_slice[\n",
    "        #     #     i] else node_slice[i + 1] - node_slice[i]  # 判断k和图节点数的大小关系\n",
    "        #     # _, topk_indices = to_sort.topk(k, dim=0)  # 返回前k个元素及对应的索引\n",
    "        #     topk_indices = Tensor(range(0, self.k))\n",
    "        #     topk_indices += node_slice[i]  # 定位到原始batch的索引\n",
    "        #     topk_indices = topk_indices.squeeze()\n",
    "        #     topk_indices = topk_indices.int()\n",
    "        #     sortpooling_graph = x.index_select(0, topk_indices)\n",
    "        #     # if k < self.k:\n",
    "        #     #     to_pad = torch.zeros(self.k - k, self.total_latent_dim)\n",
    "        #     #     if torch.cuda.is_available() and isinstance(\n",
    "        #     #             x, torch.cuda.FloatTensor):\n",
    "        #     #         to_pad = to_pad.cuda()\n",
    "        #     #     sortpooling_graph = torch.cat((sortpooling_graph, to_pad), 0)\n",
    "        #     batch_sortpooling_graphs[i] = sortpooling_graph\n",
    "\n",
    "        # step 4：traditional 1d convolution and dense layers\n",
    "        # to_conv1d = batch_sortpooling_graphs.view(\n",
    "        #     (-1, 1, self.k * self.total_latent_dim))  # 每个图变成1x1xk*totaldim的大小\n",
    "        # to_conv1d = x.view(-1, self.k, self.total_latent_dim)\n",
    "        # to_dense = torch.zeros(graph_num, self.k, 1)\n",
    "        # for i, m in enumerate(self.conv1dlist):\n",
    "        #     # out = m(to_conv1d[:, i, :].view(-1, 1, self.total_latent_dim))\n",
    "        #     to_dense[:, i, :] = m(to_conv1d[:, i, :].view(\n",
    "        #         -1, 1, self.total_latent_dim)).view(-1, 1)\n",
    "        # to_dense = to_dense.squeeze()\n",
    "        # conv1d_res = self.conv1d_params1(\n",
    "        #     to_conv1d\n",
    "        # )  # 一维卷积，一个图为一维向量，卷积核大小为单个节点特征长度，步长也为单个节点长度。输出长度为k，channel为16\n",
    "        # conv1d_res = self.conv1d_activation(conv1d_res)  # ReLU\n",
    "        # # conv1d_res = self.maxpool1d(conv1d_res)  # 窗口大小2，步长2，每个图为（k-2）/2+1\n",
    "        # # conv1d_res = self.conv1d_params2(\n",
    "        # #     conv1d_res\n",
    "        # # )  # 继续卷，这时候卷积核大小为5，步长1，输出channel为32，即一个位置有32维的embedding。长度为((k-2)/2+1)-5+1\n",
    "        # # conv1d_res = self.conv1d_activation(conv1d_res)  # ReLU\n",
    "\n",
    "        # to_dense = to_dense.view(graph_num,\n",
    "        #                          -1)  # 把channel拉平，变成G*上面的长度 x channel数\n",
    "\n",
    "        if self.output_dim > 0:\n",
    "            reluact_fp = self.out_params(x)  # 如果有output_dim，加一个线性全连接\n",
    "            # reluact_fp = self.conv1d_activation(reluact_fp)  # ReLU\n",
    "        else:\n",
    "            reluact_fp = x  # 如果没有就直接输出\n",
    "\n",
    "        # step 5: MLP classification\n",
    "        logits = self.h1_weights(reluact_fp)\n",
    "        # h1 = F.relu(h1)\n",
    "        # h1 = F.dropout(h1, training=self.training)\n",
    "        # logits = self.h2_weights(h1)\n",
    "        logits = F.log_softmax(logits, dim=1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def node_4edge_slice(self, edge_index):\n",
    "        row, _ = edge_index[0], edge_index[1]\n",
    "        row = row.cpu().numpy()\n",
    "        node_slice4edge = torch.cumsum(torch.from_numpy(np.bincount(row)), 0)\n",
    "        node_slice4edge = torch.cat([torch.tensor([0]), node_slice4edge])\n",
    "        return node_slice4edge\n",
    "\n",
    "\n",
    "path = osp.join(osp.abspath('..'), 'graph', 'PLAIDG_single')\n",
    "datasets = PLAIDDataset(root=path,\n",
    "                        name='PLAIDG_single',\n",
    "                        use_node_label=False,\n",
    "                        use_edge_attr=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DGCNN(20, datasets.num_node_features, datasets.num_edge_features,\n",
    "              datasets.num_classes).to(device)\n",
    "data = datasets.data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    loader = DataLoader(datasets, batch_size=1000, shuffle=True)\n",
    "    total_loss = []\n",
    "    for batch in loader:\n",
    "        batch.to(device)\n",
    "        out = model(batch)\n",
    "        y = batch.y\n",
    "        loss = F.nll_loss(out, y)\n",
    "        pred = out.data.max(1, keepdim=True)[1]\n",
    "        acc = pred.eq(y.data.view_as(pred)).cpu().sum().item() / float(\n",
    "            y.size()[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.data.cpu().detach().numpy()\n",
    "        total_loss.append(np.array([loss, acc]) * len(y))\n",
    "\n",
    "    total_loss = np.array(total_loss)\n",
    "    avg_loss = np.sum(total_loss, 0) / len(datasets.data.y)\n",
    "    print('epoch %d:loss %.5f acc %.5f' % (epoch, avg_loss[0], avg_loss[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:loss 11.38359 acc 0.08638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:loss 4.99706 acc 0.10138\n",
      "epoch 2:loss 2.97665 acc 0.10308\n",
      "epoch 3:loss 2.41378 acc 0.16969\n",
      "epoch 4:loss 2.28242 acc 0.19938\n",
      "epoch 5:loss 2.22329 acc 0.20777\n",
      "epoch 6:loss 2.20096 acc 0.21685\n",
      "epoch 7:loss 2.19207 acc 0.21769\n",
      "epoch 8:loss 2.18870 acc 0.22123\n",
      "epoch 9:loss 2.18644 acc 0.21815\n",
      "epoch 10:loss 2.18805 acc 0.21892\n",
      "epoch 11:loss 2.18801 acc 0.21485\n",
      "epoch 12:loss 2.18577 acc 0.21715\n",
      "epoch 13:loss 2.18684 acc 0.21815\n",
      "epoch 14:loss 2.18537 acc 0.21531\n",
      "epoch 15:loss 2.18762 acc 0.21515\n",
      "epoch 16:loss 2.18453 acc 0.21723\n",
      "epoch 17:loss 2.18301 acc 0.21962\n",
      "epoch 18:loss 2.18288 acc 0.21808\n",
      "epoch 19:loss 2.18313 acc 0.22031\n",
      "epoch 20:loss 2.18350 acc 0.21815\n",
      "epoch 21:loss 2.18240 acc 0.22062\n",
      "epoch 22:loss 2.18336 acc 0.22015\n",
      "epoch 23:loss 2.18520 acc 0.22008\n",
      "epoch 24:loss 2.18705 acc 0.21538\n",
      "epoch 25:loss 2.18305 acc 0.21800\n",
      "epoch 26:loss 2.18272 acc 0.21777\n",
      "epoch 27:loss 2.18360 acc 0.21585\n",
      "epoch 28:loss 2.18441 acc 0.21685\n",
      "epoch 29:loss 2.18378 acc 0.21877\n",
      "epoch 30:loss 2.18585 acc 0.21808\n",
      "epoch 31:loss 2.18431 acc 0.21823\n",
      "epoch 32:loss 2.18572 acc 0.21177\n",
      "epoch 33:loss 2.18498 acc 0.22054\n",
      "epoch 34:loss 2.19082 acc 0.21200\n",
      "epoch 35:loss 2.18811 acc 0.21792\n",
      "epoch 36:loss 2.18751 acc 0.22077\n",
      "epoch 37:loss 2.18690 acc 0.20915\n",
      "epoch 38:loss 2.18411 acc 0.22031\n",
      "epoch 39:loss 2.18589 acc 0.21446\n",
      "epoch 40:loss 2.18462 acc 0.21762\n",
      "epoch 41:loss 2.18457 acc 0.21631\n",
      "epoch 42:loss 2.18335 acc 0.21838\n",
      "epoch 43:loss 2.18790 acc 0.21608\n",
      "epoch 44:loss 2.18776 acc 0.21069\n",
      "epoch 45:loss 2.18406 acc 0.21515\n",
      "epoch 46:loss 2.18656 acc 0.21731\n",
      "epoch 47:loss 2.18848 acc 0.21469\n",
      "epoch 48:loss 2.18756 acc 0.21262\n",
      "epoch 49:loss 2.18815 acc 0.21277\n",
      "epoch 50:loss 2.18377 acc 0.21623\n",
      "epoch 51:loss 2.18565 acc 0.21077\n",
      "epoch 52:loss 2.18562 acc 0.21946\n",
      "epoch 53:loss 2.18579 acc 0.21646\n",
      "epoch 54:loss 2.18818 acc 0.21469\n",
      "epoch 55:loss 2.19372 acc 0.21592\n",
      "epoch 56:loss 2.19492 acc 0.20831\n",
      "epoch 57:loss 2.19169 acc 0.21500\n",
      "epoch 58:loss 2.19286 acc 0.21900\n",
      "epoch 59:loss 2.18683 acc 0.21469\n",
      "epoch 60:loss 2.18576 acc 0.21892\n",
      "epoch 61:loss 2.18356 acc 0.21715\n",
      "epoch 62:loss 2.18573 acc 0.21138\n",
      "epoch 63:loss 2.19131 acc 0.21546\n",
      "epoch 64:loss 2.18986 acc 0.21285\n",
      "epoch 65:loss 2.18657 acc 0.20862\n",
      "epoch 66:loss 2.18888 acc 0.21100\n",
      "epoch 67:loss 2.19236 acc 0.21200\n",
      "epoch 68:loss 2.19434 acc 0.20792\n",
      "epoch 69:loss 2.19149 acc 0.21308\n",
      "epoch 70:loss 2.18778 acc 0.21408\n",
      "epoch 71:loss 2.18912 acc 0.21600\n",
      "epoch 72:loss 2.18963 acc 0.21085\n",
      "epoch 73:loss 2.19059 acc 0.21854\n",
      "epoch 74:loss 2.18782 acc 0.21515\n",
      "epoch 75:loss 2.18577 acc 0.21646\n",
      "epoch 76:loss 2.18701 acc 0.21469\n",
      "epoch 77:loss 2.18743 acc 0.21792\n",
      "epoch 78:loss 2.19236 acc 0.21715\n",
      "epoch 79:loss 2.18623 acc 0.21877\n",
      "epoch 80:loss 2.18400 acc 0.21723\n",
      "epoch 81:loss 2.19181 acc 0.21446\n",
      "epoch 82:loss 2.19270 acc 0.21331\n",
      "epoch 83:loss 2.19073 acc 0.21269\n",
      "epoch 84:loss 2.18541 acc 0.21585\n",
      "epoch 85:loss 2.18494 acc 0.21908\n",
      "epoch 86:loss 2.18815 acc 0.21792\n",
      "epoch 87:loss 2.18561 acc 0.21438\n",
      "epoch 88:loss 2.18803 acc 0.21592\n",
      "epoch 89:loss 2.18720 acc 0.21692\n",
      "epoch 90:loss 2.18590 acc 0.21169\n",
      "epoch 91:loss 2.18957 acc 0.21562\n",
      "epoch 92:loss 2.18650 acc 0.21377\n",
      "epoch 93:loss 2.18649 acc 0.21538\n",
      "epoch 94:loss 2.18663 acc 0.22054\n",
      "epoch 95:loss 2.18560 acc 0.21846\n",
      "epoch 96:loss 2.18629 acc 0.21538\n",
      "epoch 97:loss 2.19068 acc 0.21662\n",
      "epoch 98:loss 2.18883 acc 0.21385\n",
      "epoch 99:loss 2.18931 acc 0.21362\n"
     ]
    }
   ],
   "source": [
    "from torch.functional import Tensor\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.io import read_tu_data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PLAIDDataset(InMemoryDataset):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 name='PLAIDG_single',\n",
    "                 transform=None,\n",
    "                 pre_transform=None,\n",
    "                 pre_filter=None,\n",
    "                 use_edge_attr=False,\n",
    "                 use_node_label=False):\n",
    "        self.name = name\n",
    "        super(PLAIDDataset, self).__init__(root, transform, pre_transform,\n",
    "                                           pre_filter)  # 预处理在这里实现\n",
    "        self.data, self.slices = torch.load(\n",
    "            self.processed_paths[0])  # 读取处理好的数据\n",
    "        if self.data.x is not None and not use_node_label:\n",
    "            num_node_attributes = self.num_node_attributes\n",
    "            self.data.x = self.data.x[:, :num_node_attributes]\n",
    "        if self.data.edge_attr is not None and not use_edge_attr:\n",
    "            num_edge_attributes = self.num_edge_attributes\n",
    "            self.data.edge_attr = self.data.edge_attr[:,\n",
    "                                                      num_edge_attributes:]  # 不需要edge_attr，只要后面的label\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return osp.join(self.root, self.name, 'raw')  # join可以自动加斜杠\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return osp.join(self.root, self.name, 'processed')\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(\n",
    "        self\n",
    "    ):  #A list of files in the raw_dir which needs to be found in order to skip the download.\n",
    "        names = [\n",
    "            'A', 'edge_attributes', 'graph_indicator', 'graph_labels',\n",
    "            'node_attributes', 'node_labels'\n",
    "        ]\n",
    "        return ['{}_{}.txt'.format('PLAIDG', name) for name in names]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(\n",
    "        self\n",
    "    ):  #A list of files in the processed_dir which needs to be found in order to skip the processing.\n",
    "        return 'data.pt'\n",
    "\n",
    "    @property\n",
    "    def num_node_labels(self) -> int:\n",
    "        if self.data.x is None:\n",
    "            return 0\n",
    "        for i in range(self.data.x.size(1)):\n",
    "            x = self.data.x[:, i:]\n",
    "            if ((x == 0) | (x == 1)).all() and (x.sum(dim=1) == 1).all():\n",
    "                return self.data.x.size(1) - i\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def num_node_attributes(self) -> int:\n",
    "        if self.data.x is None:\n",
    "            return 0\n",
    "        return self.data.x.size(1) - self.num_node_labels\n",
    "\n",
    "    @property\n",
    "    def num_edge_labels(self) -> int:\n",
    "        if self.data.edge_attr is None:\n",
    "            return 0\n",
    "        for i in range(self.data.edge_attr.size(1)):\n",
    "            if self.data.edge_attr[:, i:].sum() == self.data.edge_attr.size(0):\n",
    "                return self.data.edge_attr.size(1) - i\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def num_edge_attributes(self) -> int:\n",
    "        if self.data.edge_attr is None:\n",
    "            return 0\n",
    "        return self.data.edge_attr.size(1) - self.num_edge_labels\n",
    "\n",
    "    def download(self):\n",
    "        print('This dataset is not yet public')\n",
    "\n",
    "    def process(self):\n",
    "        self.data, self.slices = read_tu_data(self.raw_dir, 'PLAIDG')\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [self.get(idx) for idx in range(len(self))]\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "            self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.get(idx) for idx in range(len(self))]  #拆成一个个单图\n",
    "            data_list = [self.pre_transform(data)\n",
    "                         for data in data_list]  #对每个单图进行pre_transform\n",
    "            self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "        torch.save((self.data, self.slices), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({})'.format(self.name, len(self))\n",
    "\n",
    "\n",
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim,\n",
    "        num_node_feats,\n",
    "        num_edge_feats,\n",
    "        num_class,\n",
    "        latent_dim=[1, 1],\n",
    "        k=34,\n",
    "        conv1d_channels=[1, 32],\n",
    "        conv1d_kws=[0, 5],  # 0是待定的意思\n",
    "        conv1d_activation='ReLU',\n",
    "    ):\n",
    "        super(DGCNN, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim  # 指的是图卷积里面的每个层的节点特征维度，最后一层为1，论文写着方便排序\n",
    "        self.output_dim = output_dim  # 指的是图卷积之后输出的维度，如果有dense则输出dense之后的，没有dense就输出dense\n",
    "        self.num_node_feats = num_node_feats  # dataset.num_node_features\n",
    "        self.num_edge_feats = num_edge_feats  # dataset.num_edge_features\n",
    "        self.k = k\n",
    "        self.total_latent_dim = sum(latent_dim)\n",
    "        conv1d_kws[0] = self.total_latent_dim  # 把所有图层拼接起来作为1-D卷积的输入\n",
    "        self.hidden_dim = int(math.sqrt(output_dim * num_class))\n",
    "\n",
    "        # GCN\n",
    "        self.conv1 = GCNConv(self.num_node_feats, self.latent_dim[0])\n",
    "        self.conv2 = GCNConv(self.latent_dim[0], self.latent_dim[1])\n",
    "\n",
    "        self.conv1dlist = nn.ModuleList([\n",
    "            nn.Conv1d(1, conv1d_channels[0], conv1d_kws[0]) for i in range(k)\n",
    "        ])\n",
    "        self.dense_dim = k\n",
    "        if self.output_dim > 0:\n",
    "            self.out_params = nn.Linear(self.dense_dim, output_dim)  #最后加个全连接\n",
    "\n",
    "        self.conv1d_activation = eval('nn.{}()'.format(conv1d_activation))\n",
    "\n",
    "        # MLPClassifier\n",
    "        self.h1_weights = nn.Linear(output_dim, num_class)\n",
    "\n",
    "        # initial parameter\n",
    "        # if needed\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_attr, edge_index = data.x, data.edge_attr, data.edge_index\n",
    "\n",
    "        graph_num = len(np.unique(\n",
    "            data.batch))  # len(np.unique(batch.batch))为batch中几个图\n",
    "        node_slice = torch.cumsum(torch.from_numpy(np.bincount(data.batch)), 0)\n",
    "        node_slice = torch.cat([torch.tensor([0]), node_slice])\n",
    "\n",
    "        \n",
    "\n",
    "        # # step 2: propagate the message via 4 GCN layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        # # x = torch.cat([x, out], 1)\n",
    "        # x = out\n",
    "        # out = self.conv2(out, edge_index)\n",
    "        # x = torch.cat([x, out], 1)\n",
    "        # out = self.conv3(out, edge_index)\n",
    "        # x = torch.cat([x, out], 1)\n",
    "        # out = self.conv4(out, edge_index)  # 最后一层GCN的输出，N*1维，作为sortpooling排序用\n",
    "        # x = torch.cat([x, out], 1)\n",
    "\n",
    "        # step 3: sortpooling layer\n",
    "        # 因为batch里不止一张图，所以要区分每个图单独进行sortpooling\n",
    "        # batch_sortpooling_graphs = torch.zeros(graph_num, self.k,\n",
    "        #                                        self.total_latent_dim)\n",
    "        # if torch.cuda.is_available() and isinstance(x, torch.cuda.FloatTensor):\n",
    "        #     batch_sortpooling_graphs = batch_sortpooling_graphs.cuda()\n",
    "\n",
    "        # for i in range(graph_num):\n",
    "        #     # to_sort = out[node_slice[i]:node_slice[i + 1]]  # 把当前graph的节点特征拿出来\n",
    "        #     # k = self.k if self.k <= node_slice[i + 1] - node_slice[\n",
    "        #     #     i] else node_slice[i + 1] - node_slice[i]  # 判断k和图节点数的大小关系\n",
    "        #     # _, topk_indices = to_sort.topk(k, dim=0)  # 返回前k个元素及对应的索引\n",
    "        #     topk_indices = Tensor(range(0, self.k))\n",
    "        #     topk_indices += node_slice[i]  # 定位到原始batch的索引\n",
    "        #     topk_indices = topk_indices.squeeze()\n",
    "        #     topk_indices = topk_indices.int()\n",
    "        #     sortpooling_graph = x.index_select(0, topk_indices)\n",
    "        #     # if k < self.k:\n",
    "        #     #     to_pad = torch.zeros(self.k - k, self.total_latent_dim)\n",
    "        #     #     if torch.cuda.is_available() and isinstance(\n",
    "        #     #             x, torch.cuda.FloatTensor):\n",
    "        #     #         to_pad = to_pad.cuda()\n",
    "        #     #     sortpooling_graph = torch.cat((sortpooling_graph, to_pad), 0)\n",
    "        #     batch_sortpooling_graphs[i] = sortpooling_graph\n",
    "\n",
    "        # step 4：traditional 1d convolution and dense layers\n",
    "        # to_conv1d = batch_sortpooling_graphs.view(\n",
    "        #     (-1, 1, self.k * self.total_latent_dim))  # 每个图变成1x1xk*totaldim的大小\n",
    "        # to_conv1d = x.view(-1, self.k, self.total_latent_dim)\n",
    "        # to_dense = torch.zeros(graph_num, self.k, 1)\n",
    "        # for i, m in enumerate(self.conv1dlist):\n",
    "        #     # out = m(to_conv1d[:, i, :].view(-1, 1, self.total_latent_dim))\n",
    "        #     to_dense[:, i, :] = m(to_conv1d[:, i, :].view(\n",
    "        #         -1, 1, self.total_latent_dim)).view(-1, 1)\n",
    "        # to_dense = to_dense.squeeze()\n",
    "        # conv1d_res = self.conv1d_params1(\n",
    "        #     to_conv1d\n",
    "        # )  # 一维卷积，一个图为一维向量，卷积核大小为单个节点特征长度，步长也为单个节点长度。输出长度为k，channel为16\n",
    "        # conv1d_res = self.conv1d_activation(conv1d_res)  # ReLU\n",
    "        # # conv1d_res = self.maxpool1d(conv1d_res)  # 窗口大小2，步长2，每个图为（k-2）/2+1\n",
    "        # # conv1d_res = self.conv1d_params2(\n",
    "        # #     conv1d_res\n",
    "        # # )  # 继续卷，这时候卷积核大小为5，步长1，输出channel为32，即一个位置有32维的embedding。长度为((k-2)/2+1)-5+1\n",
    "        # # conv1d_res = self.conv1d_activation(conv1d_res)  # ReLU\n",
    "\n",
    "        # to_dense = to_dense.view(graph_num,\n",
    "        #                          -1)  # 把channel拉平，变成G*上面的长度 x channel数\n",
    "        x = x.view(graph_num, -1)\n",
    "\n",
    "        if self.output_dim > 0:\n",
    "            reluact_fp = self.out_params(x)  # 如果有output_dim，加一个线性全连接\n",
    "            # reluact_fp = self.conv1d_activation(reluact_fp)  # ReLU\n",
    "        else:\n",
    "            reluact_fp = x  # 如果没有就直接输出\n",
    "\n",
    "        # step 5: MLP classification\n",
    "        logits = self.h1_weights(reluact_fp)\n",
    "        # h1 = F.relu(h1)\n",
    "        # h1 = F.dropout(h1, training=self.training)\n",
    "        # logits = self.h2_weights(h1)\n",
    "        logits = F.log_softmax(logits, dim=1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def node_4edge_slice(self, edge_index):\n",
    "        row, _ = edge_index[0], edge_index[1]\n",
    "        row = row.cpu().numpy()\n",
    "        node_slice4edge = torch.cumsum(torch.from_numpy(np.bincount(row)), 0)\n",
    "        node_slice4edge = torch.cat([torch.tensor([0]), node_slice4edge])\n",
    "        return node_slice4edge\n",
    "\n",
    "\n",
    "path = osp.join(osp.abspath('..'), 'graph', 'PLAIDG_single')\n",
    "datasets = PLAIDDataset(root=path,\n",
    "                        name='PLAIDG_single',\n",
    "                        use_node_label=False,\n",
    "                        use_edge_attr=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DGCNN(20, datasets.num_node_features, datasets.num_edge_features,\n",
    "              datasets.num_classes).to(device)\n",
    "data = datasets.data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    loader = DataLoader(datasets, batch_size=1000, shuffle=True)\n",
    "    total_loss = []\n",
    "    for batch in loader:\n",
    "        batch.to(device)\n",
    "        out = model(batch)\n",
    "        y = batch.y\n",
    "        loss = F.nll_loss(out, y)\n",
    "        pred = out.data.max(1, keepdim=True)[1]\n",
    "        acc = pred.eq(y.data.view_as(pred)).cpu().sum().item() / float(\n",
    "            y.size()[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.data.cpu().detach().numpy()\n",
    "        total_loss.append(np.array([loss, acc]) * len(y))\n",
    "\n",
    "    total_loss = np.array(total_loss)\n",
    "    avg_loss = np.sum(total_loss, 0) / len(datasets.data.y)\n",
    "    print('epoch %d:loss %.5f acc %.5f' % (epoch, avg_loss[0], avg_loss[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为GCN的参数不能同时异构节点之间的关系，所以无法收敛\n",
    "有没有可能是一个断面作为一个节点，然后节点定义好内容，能够代表某些信息。或者说怎么能够考虑单个断面的稳定数据，还能考虑时序问题。每个节点都做一个识别\n",
    "统计一下各类特征同时出现的频次？然后制定备选集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个节点都是一个样本，节点标签是设备类型，那怎么构建节点属性和边呢？新节点怎么放进去？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
